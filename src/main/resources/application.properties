# Application Configuration
spring.application.name=postgres-csv-loader

# Current Active Profile: DEFAULT (Local Development)
# To use other profiles: mvn spring-boot:run -Dspring.profiles.active=dev

# Server Configuration
server.port=8081

# Database Configuration (Local PostgreSQL)
# Make sure PostgreSQL is running on localhost:5432
spring.datasource.url=jdbc:postgresql://localhost:5432/postgres?currentSchema=title_d_app
spring.datasource.username=postgres
spring.datasource.password=admin
spring.datasource.driver-class-name=org.postgresql.Driver
spring.datasource.schema=title_d_app


# Database Configuration (Dev PostgreSQL)
# spring.datasource.url=jdbc:postgresql://az1ompdbvlut202:5432/omp04u
# spring.datasource.username=gmanda01
# spring.datasource.password=gmanda01_1234
# spring.datasource.driver-class-name=org.postgresql.Driver
# spring.datasource.schema=title_d_app

# JPA/Hibernate Configuration
spring.jpa.database-platform=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.show-sql=false
spring.jpa.hibernate.ddl-auto=none
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.jdbc.batch_size=20
spring.jpa.properties.hibernate.order_inserts=true
spring.jpa.properties.hibernate.order_updates=true
spring.jpa.open-in-view=false
# Force Hibernate to use PostgreSQL-specific types
spring.jpa.properties.hibernate.jdbc.use_get_generated_keys=true
spring.jpa.properties.hibernate.type.preferred_instant_jdbc_type=TIMESTAMP
# Register custom PostgreSQL types
spring.jpa.properties.hibernate.type.wrapper_array_handling=ALLOW

# HikariCP Connection Pool Configuration
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.idle-timeout=300000
spring.datasource.hikari.connection-timeout=30000

# Database Migration Configuration
# Flyway enabled for automatic schema management
spring.flyway.enabled=true
spring.flyway.locations=classpath:db/migration
spring.flyway.baseline-on-migrate=true
spring.flyway.schemas=public,audit,staging,core,title_d_app
# spring.flyway.baseline-on-migrate=true

# Application Monitoring Configuration
management.endpoints.web.exposure.include=health,info,metrics
management.endpoint.health.show-details=when-authorized

# CSV Processing Configuration
csv.processing.batch-size=1000
csv.processing.max-file-size=100MB
csv.processing.temp-directory=${java.io.tmpdir}/csv-loader

# File Upload Configuration
spring.servlet.multipart.max-file-size=500MB
spring.servlet.multipart.max-request-size=500MB
spring.servlet.multipart.file-size-threshold=10MB
spring.servlet.multipart.resolve-lazily=false

# Application Logging Configuration
# Logging levels: TRACE < DEBUG < INFO < WARN < ERROR
# INFO for production, DEBUG for development troubleshooting
logging.level.teranet.mapdev.ingest=INFO
logging.level.org.springframework.jdbc=WARN
logging.level.org.springframework.orm.jpa=WARN
logging.level.org.hibernate.SQL=WARN
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=WARN
logging.level.org.flywaydb=INFO
logging.level.root=INFO

# Logging file configuration (managed by logback-spring.xml)
logging.file.name=logs/csv-loader.log
logging.file.path=logs

# Console pattern with correlation ID
logging.pattern.console=[%d{yyyy-MM-dd HH:mm:ss}] [%thread] [%X{correlationId:-NO-CORRELATION-ID}] %-5level %logger{36} - %msg%n

# ========================================
# WATCH FOLDER CONFIGURATION
# ========================================

# Enable/disable watch folder functionality
watch.folder.enabled=true

# Folder paths (use forward slashes even on Windows for consistency)
watch.folder.root=C:/data/csv-loader
# watch.folder.root=\\\\mrkompapvwut12\\data\\csv-loader
watch.folder.upload=${watch.folder.root}/upload
watch.folder.wip=${watch.folder.root}/wip
watch.folder.error=${watch.folder.root}/error
watch.folder.archive=${watch.folder.root}/archive

# Marker file settings
watch.folder.use-marker-files=true
watch.folder.marker-extension=.done

# File stability checks
watch.folder.stability-check-delay=2000
watch.folder.stability-check-retries=3

# Processing settings
watch.folder.polling-interval=5000
watch.folder.max-concurrent-files=5
# Supported file extensions (comma-separated, empty string for files without extension)
# Example: .csv,.zip, (empty after comma means files with no extension are allowed)
watch.folder.supported-extensions=.csv,.zip,

# Retention policies (days)
watch.folder.archive.retention-days=90
watch.folder.error.retention-days=30
watch.folder.cleanup.enabled=true
watch.folder.cleanup.cron=0 0 2 * * *

# Watch folder logging
logging.level.teranet.mapdev.ingest.service.WatchFolderService=INFO
logging.level.teranet.mapdev.ingest.service.WatchFolderManager=INFO

logging.config=classpath:log4j2.properties


# ========================================
# API UPLOAD CONFIGURATION
# ========================================
# API Upload - Default file format (csv or tsv)
# This is used when:
# 1. File has no extension (e.g., PM162, IM362)
# 2. Format cannot be inferred from file extension
# 3. Format is not explicitly specified in API request
ingest.api.default-format=tsv

# API Upload - Supported file extensions (comma-separated)
# Leave empty to allow files without extensions
# Examples: csv,tsv,txt or leave empty for no-extension files
ingest.api.supported-extensions=

# Infer format from file extension (.csv -> csv, .tsv -> tsv)
# For files without extensions, uses ingest.api.default-format
ingest.api.infer-format-from-extension=true

# ========================================
# DELIMITER & FORMAT CONFIGURATION
# ========================================
# TSV-specific settings
ingest.tsv.delimiter=\t
ingest.tsv.has-headers=false    

# CSV-specific settings
ingest.csv.has-headers=true

# ========================================
# FILENAME ROUTING CONFIGURATION
# ========================================
# Enable filename-based table routing (for legacy Polaris files like PM162, IM362)
# Set to true to enable routing files like PM162 -> staging_pm1
ingest.filename-routing.enabled=true

# Regex pattern to extract table identifier from filename
# Example: ^([A-Z]{2})(\\d)(?:\\d{2})$ matches PM162 -> groups: PM, 1
ingest.filename-routing.regex=^([A-Z]{2})(\\d)(?:\\d{2})$

# Template to construct table name from regex groups
# Example: ${g1}${g2} transforms (PM, 1) -> PM1
ingest.filename-routing.template=${g1}${g2}

# Target schema for filename-routed tables (Not required, use spring.datasource.schema)
# ingest.target.schema=title_d_app

# ========================================
# STAGING TABLES CONFIGURATION
# ========================================
# List of main tables for staging table creation and validation
# These tables are required for file processing
ingest.main-tables=im1,im2,im3,pm1,pm2,pm3,pm4,pm5,pm6,pm7

# Infer format from file extension (.csv -> csv, .tsv -> tsv)
# For files without extensions, format must be explicitly specified in API request
ingest.infer-format-from-extension=true
