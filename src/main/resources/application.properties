# Application Configuration
spring.application.name=postgres-csv-loader

# Current Active Profile: DEFAULT (Local Development)
# To use other profiles: mvn spring-boot:run -Dspring.profiles.active=dev

# Server Configuration
server.port=8081

# Database Configuration (Local PostgreSQL)
# Make sure PostgreSQL is running on localhost:5432
# spring.datasource.url=jdbc:postgresql://localhost:5432/postgres
# spring.datasource.username=postgres
# spring.datasource.password=admin
# spring.datasource.driver-class-name=org.postgresql.Driver


# Database Configuration (Dev PostgreSQL)
spring.datasource.url=jdbc:postgresql://az1ompdbvlut202:5432/omp04u
spring.datasource.username=gmanda01
spring.datasource.password=gmanda01_1234
spring.datasource.driver-class-name=org.postgresql.Driver
spring.datasource.schema=title_d_app

# JPA/Hibernate Configuration
spring.jpa.database-platform=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.show-sql=false
spring.jpa.hibernate.ddl-auto=none
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.jdbc.batch_size=20
spring.jpa.properties.hibernate.order_inserts=true
spring.jpa.properties.hibernate.order_updates=true
spring.jpa.open-in-view=false
# Force Hibernate to use PostgreSQL-specific types
spring.jpa.properties.hibernate.jdbc.use_get_generated_keys=true
spring.jpa.properties.hibernate.type.preferred_instant_jdbc_type=TIMESTAMP
# Register custom PostgreSQL types
spring.jpa.properties.hibernate.type.wrapper_array_handling=ALLOW

# HikariCP Connection Pool Configuration
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.idle-timeout=300000
spring.datasource.hikari.connection-timeout=30000

# Database Migration Configuration
# Flyway disabled - using custom DatabaseInitializer for table creation
spring.flyway.enabled=false
# spring.flyway.locations=classpath:db/migration
# spring.flyway.baseline-on-migrate=true

# Application Monitoring Configuration
management.endpoints.web.exposure.include=health,info,metrics
management.endpoint.health.show-details=when-authorized

# CSV Processing Configuration
csv.processing.batch-size=1000
csv.processing.max-file-size=100MB
csv.processing.temp-directory=${java.io.tmpdir}/csv-loader

# Staging Table Configuration
# Prefix for all staging tables (default: staging)
# Tables will be named: {prefix}_{filename}_{batchId}
csv.processing.staging-table-prefix=staging

# File Upload Configuration
spring.servlet.multipart.max-file-size=500MB
spring.servlet.multipart.max-request-size=500MB
spring.servlet.multipart.file-size-threshold=10MB
spring.servlet.multipart.resolve-lazily=false

# Application Logging Configuration
# Logging levels: TRACE < DEBUG < INFO < WARN < ERROR
# INFO for production, DEBUG for development troubleshooting
logging.level.teranet.mapdev.ingest=INFO
logging.level.org.springframework.jdbc=WARN
logging.level.org.springframework.orm.jpa=WARN
logging.level.org.hibernate.SQL=WARN
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=WARN
logging.level.org.flywaydb=INFO
logging.level.root=INFO

# Logging file configuration (managed by logback-spring.xml)
logging.file.name=logs/csv-loader.log
logging.file.path=logs

# Console pattern with correlation ID
logging.pattern.console=[%d{yyyy-MM-dd HH:mm:ss}] [%thread] [%X{correlationId:-NO-CORRELATION-ID}] %-5level %logger{36} - %msg%n

# ========================================
# WATCH FOLDER CONFIGURATION
# ========================================

# Enable/disable watch folder functionality
watch.folder.enabled=true

# Folder paths (use forward slashes even on Windows for consistency)
# watch.folder.root=C:/data/csv-loader
watch.folder.root=\\\\mrkompapvwut12\\data\\csv-loader
watch.folder.upload=${watch.folder.root}/upload
watch.folder.wip=${watch.folder.root}/wip
watch.folder.error=${watch.folder.root}/error
watch.folder.archive=${watch.folder.root}/archive

# Marker file settings
watch.folder.use-marker-files=true
watch.folder.marker-extension=.done

# File stability checks
watch.folder.stability-check-delay=2000
watch.folder.stability-check-retries=3

# Processing settings
watch.folder.polling-interval=5000
watch.folder.max-concurrent-files=5
watch.folder.supported-extensions=.csv,.zip

# Retention policies (days)
watch.folder.archive.retention-days=90
watch.folder.error.retention-days=30
watch.folder.cleanup.enabled=true
watch.folder.cleanup.cron=0 0 2 * * *

# Watch folder logging
logging.level.teranet.mapdev.ingest.service.WatchFolderService=INFO
logging.level.teranet.mapdev.ingest.service.WatchFolderManager=INFO

logging.config=classpath:log4j2.properties


# ========================================
# DELIMITER & FORMAT CONFIGURATION
# ========================================
# Default file format for ingestion (csv or tsv)
ingest.default-format=csv

# TSV-specific settings
ingest.tsv.delimiter=\t
ingest.tsv.has-headers=false    

# CSV-specific settings
ingest.csv.has-headers=true

# ========================================
# FILENAME ROUTING CONFIGURATION
# ========================================
# Enable filename-based table routing (for legacy Polaris files like PM162, IM362)
ingest.filename-routing.enabled=false

# Regex pattern to extract table identifier from filename
# Example: ^([A-Z]{2})(\\d)(?:\\d{2})$ matches PM162 -> groups: PM, 1
ingest.filename-routing.regex=^([A-Z]{2})(\\d)(?:\\d{2})$

# Template to construct table name from regex groups
# Example: ${g1}${g2} transforms (PM, 1) -> PM1
ingest.filename-routing.template=${g1}${g2}

# Target schema for filename-routed tables (Not required, use spring.datasource.schema)
# ingest.target.schema=title_d_app

# Infer format from file extension (.csv -> csv, .tsv -> tsv)
ingest.infer-format-from-extension=true

# List of main tables for staging table creation
ingest.main-tables=im1,im2,im3,pm1,pm2,pm3,pm4,pm5,pm6,pm7